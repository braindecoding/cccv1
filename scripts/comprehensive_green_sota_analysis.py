"""
Comprehensive Green SOTA Analysis
=================================

Complete green computing analysis comparing CCCV1 vs all SOTA methods
for academic-grade sustainability assessment.
"""

import torch
import time
import numpy as np
from pathlib import Path
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# Import models
import sys
sys.path.append('src')
sys.path.append('sota_comparison')
from models.cortexflow_clip_cnn_v1 import create_cccv1_model

class ComprehensiveGreenAnalyzer:
    """Complete green analysis for all SOTA methods"""
    
    def __init__(self, device='cuda'):
        self.device = device
        self.results = {}
        
    def count_parameters(self, model):
        """Count total and trainable parameters"""
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        return total_params, trainable_params
    
    def measure_inference_time(self, model, input_tensor, num_runs=100):
        """Measure inference time with proper synchronization"""
        model.eval()
        
        # Warmup
        with torch.no_grad():
            for _ in range(10):
                try:
                    output = model(input_tensor)
                except Exception as e:
                    print(f"      ‚ö†Ô∏è Warmup failed: {e}")
                    return float('inf')
        
        # Synchronize GPU if available
        if self.device == 'cuda':
            torch.cuda.synchronize()
        
        # Measure inference time
        start_time = time.time()
        
        with torch.no_grad():
            for _ in range(num_runs):
                try:
                    output = model(input_tensor)
                except Exception as e:
                    print(f"      ‚ö†Ô∏è Inference failed: {e}")
                    return float('inf')
        
        if self.device == 'cuda':
            torch.cuda.synchronize()
        
        end_time = time.time()
        avg_time = (end_time - start_time) / num_runs
        
        return avg_time
    
    def measure_memory_usage(self, model, input_tensor):
        """Measure GPU memory usage"""
        if self.device == 'cuda':
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()
            
            try:
                # Forward pass
                model.eval()
                with torch.no_grad():
                    output = model(input_tensor)
                
                memory_used = torch.cuda.max_memory_allocated() / (1024**2)  # MB
                return memory_used
            except Exception as e:
                print(f"      ‚ö†Ô∏è Memory measurement failed: {e}")
                return float('inf')
        else:
            return 0
    
    def calculate_carbon_footprint(self, total_params, training_time_hours, inference_time_ms):
        """Calculate carbon footprint based on model complexity"""
        
        # GPU power consumption (Watts) - RTX 3060
        gpu_power = 170
        
        # Carbon intensity (kg CO2/kWh) - global average
        carbon_intensity = 0.5
        
        # Training carbon footprint (based on model complexity)
        training_power_kwh = (gpu_power / 1000) * training_time_hours
        training_carbon = training_power_kwh * carbon_intensity
        
        # Inference carbon footprint (per 1000 inferences)
        if inference_time_ms == float('inf'):
            inference_carbon = float('inf')
        else:
            inference_power_kwh = (gpu_power / 1000) * (inference_time_ms * 1000 / 3600000)
            inference_carbon = inference_power_kwh * carbon_intensity
        
        total_carbon = training_carbon + inference_carbon
        
        return {
            'training_carbon_kg': training_carbon,
            'inference_carbon_kg': inference_carbon,
            'total_carbon_kg': total_carbon
        }
    
    def analyze_cccv1(self, dataset_name, input_dim):
        """Analyze CCCV1 model"""
        print(f"   üå± Analyzing CCCV1-Optimized...")
        
        try:
            model = create_cccv1_model(input_dim, self.device, dataset_name, optimized=True)
            batch_size = 8
            input_tensor = torch.randn(batch_size, input_dim, device=self.device)
            
            # Measurements
            total_params, trainable_params = self.count_parameters(model)
            model_size_mb = sum(p.numel() * 4 for p in model.parameters()) / (1024**2)
            inference_time = self.measure_inference_time(model, input_tensor)
            memory_usage = self.measure_memory_usage(model, input_tensor)
            
            # Estimate training time based on model complexity
            estimated_training_hours = (total_params / 1e6) * 0.5
            
            # Carbon footprint
            carbon_footprint = self.calculate_carbon_footprint(total_params, estimated_training_hours, inference_time * 1000)
            
            results = {
                'method': 'CCCV1-Optimized',
                'dataset': dataset_name,
                'parameters': {
                    'total': total_params,
                    'trainable': trainable_params,
                    'size_mb': model_size_mb
                },
                'performance': {
                    'inference_time_ms': inference_time * 1000,
                    'memory_usage_mb': memory_usage,
                    'estimated_training_hours': estimated_training_hours
                },
                'environmental': carbon_footprint,
                'efficiency': {
                    'params_per_mb': total_params / model_size_mb,
                    'inference_fps': 1 / inference_time if inference_time != float('inf') else 0,
                    'carbon_efficiency': 1 / carbon_footprint['total_carbon_kg'] if carbon_footprint['total_carbon_kg'] != float('inf') else 0
                }
            }
            
            print(f"      ‚úÖ Parameters: {total_params:,} ({model_size_mb:.1f} MB)")
            print(f"      ‚ö° Inference: {inference_time*1000:.2f} ms")
            print(f"      üíæ Memory: {memory_usage:.1f} MB")
            print(f"      üåç Carbon: {carbon_footprint['total_carbon_kg']:.4f} kg CO‚ÇÇ")
            
            return results
            
        except Exception as e:
            print(f"      ‚ùå CCCV1 analysis failed: {e}")
            return None
    
    def analyze_mind_vis(self, dataset_name, input_dim):
        """Analyze Mind-Vis model with simplified approach"""
        print(f"   üß† Analyzing Mind-Vis...")
        
        try:
            # Create simplified Mind-Vis model for analysis
            class SimplifiedMindVis(torch.nn.Module):
                def __init__(self, input_dim):
                    super().__init__()
                    # Simplified architecture based on Mind-Vis paper
                    self.encoder = torch.nn.Sequential(
                        torch.nn.Linear(input_dim, 2048),
                        torch.nn.ReLU(),
                        torch.nn.Linear(2048, 1024),
                        torch.nn.ReLU(),
                        torch.nn.Linear(1024, 512)
                    )
                    self.decoder = torch.nn.Sequential(
                        torch.nn.Linear(512, 1024),
                        torch.nn.ReLU(),
                        torch.nn.Linear(1024, 2048),
                        torch.nn.ReLU(),
                        torch.nn.Linear(2048, 224*224*3)  # Image output
                    )
                    self.contrastive_head = torch.nn.Linear(512, 512)
                
                def forward(self, x):
                    latent = self.encoder(x)
                    visual = self.decoder(latent)
                    contrastive = self.contrastive_head(latent)
                    return latent, visual, contrastive
            
            model = SimplifiedMindVis(input_dim).to(self.device)
            batch_size = 8
            input_tensor = torch.randn(batch_size, input_dim, device=self.device)
            
            # Measurements
            total_params, trainable_params = self.count_parameters(model)
            model_size_mb = sum(p.numel() * 4 for p in model.parameters()) / (1024**2)
            inference_time = self.measure_inference_time(model, input_tensor)
            memory_usage = self.measure_memory_usage(model, input_tensor)
            
            # Estimate training time (Mind-Vis typically requires more training)
            estimated_training_hours = (total_params / 1e6) * 1.2  # More complex training
            
            # Carbon footprint
            carbon_footprint = self.calculate_carbon_footprint(total_params, estimated_training_hours, inference_time * 1000)
            
            results = {
                'method': 'Mind-Vis',
                'dataset': dataset_name,
                'parameters': {
                    'total': total_params,
                    'trainable': trainable_params,
                    'size_mb': model_size_mb
                },
                'performance': {
                    'inference_time_ms': inference_time * 1000,
                    'memory_usage_mb': memory_usage,
                    'estimated_training_hours': estimated_training_hours
                },
                'environmental': carbon_footprint,
                'efficiency': {
                    'params_per_mb': total_params / model_size_mb,
                    'inference_fps': 1 / inference_time if inference_time != float('inf') else 0,
                    'carbon_efficiency': 1 / carbon_footprint['total_carbon_kg'] if carbon_footprint['total_carbon_kg'] != float('inf') else 0
                }
            }
            
            print(f"      ‚úÖ Parameters: {total_params:,} ({model_size_mb:.1f} MB)")
            print(f"      ‚ö° Inference: {inference_time*1000:.2f} ms")
            print(f"      üíæ Memory: {memory_usage:.1f} MB")
            print(f"      üåç Carbon: {carbon_footprint['total_carbon_kg']:.4f} kg CO‚ÇÇ")
            
            return results
            
        except Exception as e:
            print(f"      ‚ùå Mind-Vis analysis failed: {e}")
            return None
    
    def analyze_brain_diffuser(self, dataset_name, input_dim):
        """Analyze Brain-Diffuser model with simplified approach"""
        print(f"   üß¨ Analyzing Lightweight-Brain-Diffuser...")
        
        try:
            # Create simplified Brain-Diffuser model for analysis
            class SimplifiedBrainDiffuser(torch.nn.Module):
                def __init__(self, input_dim):
                    super().__init__()
                    # Simplified two-stage architecture
                    # Stage 1: VDVAE encoder
                    self.vdvae_encoder = torch.nn.Sequential(
                        torch.nn.Linear(input_dim, 1024),
                        torch.nn.ReLU(),
                        torch.nn.Linear(1024, 512),
                        torch.nn.ReLU(),
                        torch.nn.Linear(512, 256)
                    )
                    # Stage 2: Diffusion decoder
                    self.diffusion_decoder = torch.nn.Sequential(
                        torch.nn.Linear(256, 512),
                        torch.nn.ReLU(),
                        torch.nn.Linear(512, 1024),
                        torch.nn.ReLU(),
                        torch.nn.Linear(1024, 224*224*3)  # Image output
                    )
                    # Lightweight components
                    self.noise_predictor = torch.nn.Linear(256, 256)
                
                def forward(self, x, use_diffusion=True):
                    latent = self.vdvae_encoder(x)
                    if use_diffusion:
                        noise = self.noise_predictor(latent)
                        # Simplified diffusion process
                        denoised = latent + 0.1 * noise
                        output = self.diffusion_decoder(denoised)
                    else:
                        output = self.diffusion_decoder(latent)
                    return latent, output
            
            model = SimplifiedBrainDiffuser(input_dim).to(self.device)
            batch_size = 8
            input_tensor = torch.randn(batch_size, input_dim, device=self.device)
            
            # Measurements
            total_params, trainable_params = self.count_parameters(model)
            model_size_mb = sum(p.numel() * 4 for p in model.parameters()) / (1024**2)
            inference_time = self.measure_inference_time(model, input_tensor)
            memory_usage = self.measure_memory_usage(model, input_tensor)
            
            # Estimate training time (Two-stage training is more expensive)
            estimated_training_hours = (total_params / 1e6) * 1.5  # Two-stage training
            
            # Carbon footprint
            carbon_footprint = self.calculate_carbon_footprint(total_params, estimated_training_hours, inference_time * 1000)
            
            results = {
                'method': 'Lightweight-Brain-Diffuser',
                'dataset': dataset_name,
                'parameters': {
                    'total': total_params,
                    'trainable': trainable_params,
                    'size_mb': model_size_mb
                },
                'performance': {
                    'inference_time_ms': inference_time * 1000,
                    'memory_usage_mb': memory_usage,
                    'estimated_training_hours': estimated_training_hours
                },
                'environmental': carbon_footprint,
                'efficiency': {
                    'params_per_mb': total_params / model_size_mb,
                    'inference_fps': 1 / inference_time if inference_time != float('inf') else 0,
                    'carbon_efficiency': 1 / carbon_footprint['total_carbon_kg'] if carbon_footprint['total_carbon_kg'] != float('inf') else 0
                }
            }
            
            print(f"      ‚úÖ Parameters: {total_params:,} ({model_size_mb:.1f} MB)")
            print(f"      ‚ö° Inference: {inference_time*1000:.2f} ms")
            print(f"      üíæ Memory: {memory_usage:.1f} MB")
            print(f"      üåç Carbon: {carbon_footprint['total_carbon_kg']:.4f} kg CO‚ÇÇ")
            
            return results
            
        except Exception as e:
            print(f"      ‚ùå Brain-Diffuser analysis failed: {e}")
            return None
    
    def run_comprehensive_analysis(self):
        """Run complete green analysis for all methods"""
        print("üå± COMPREHENSIVE GREEN SOTA ANALYSIS")
        print("=" * 60)
        print("üéØ Analyzing computational efficiency and environmental impact")
        print("üåç Methods: CCCV1, Mind-Vis, Lightweight-Brain-Diffuser")
        
        # Test configurations - ALL 4 DATASETS for complete academic integrity
        configs = [
            {'name': 'miyawaki', 'input_dim': 967},
            {'name': 'vangerven', 'input_dim': 3092},
            {'name': 'crell', 'input_dim': 3092},
            {'name': 'mindbigdata', 'input_dim': 3092}
        ]
        
        for config in configs:
            print(f"\nüìä Dataset: {config['name'].upper()} (input_dim: {config['input_dim']})")
            print("-" * 40)
            
            dataset_results = {}
            
            # Analyze all methods
            methods = [
                ('CCCV1', self.analyze_cccv1),
                ('Mind-Vis', self.analyze_mind_vis),
                ('Brain-Diffuser', self.analyze_brain_diffuser)
            ]
            
            for method_name, analyze_func in methods:
                result = analyze_func(config['name'], config['input_dim'])
                if result:
                    dataset_results[method_name] = result
            
            self.results[config['name']] = dataset_results
        
        return self.results

def main():
    """Run comprehensive green SOTA analysis"""
    
    print("üå± STARTING COMPREHENSIVE GREEN SOTA ANALYSIS")
    print("=" * 60)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    analyzer = ComprehensiveGreenAnalyzer(device)
    
    # Run analysis
    results = analyzer.run_comprehensive_analysis()
    
    # Save results
    output_dir = Path("results/green_neural_decoding")
    output_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = output_dir / f"comprehensive_green_sota_results_{timestamp}.json"
    
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nüéâ COMPREHENSIVE GREEN SOTA ANALYSIS COMPLETE!")
    print("=" * 60)
    print(f"üìä Results saved: {results_file}")
    print(f"üå± Ready for complete green AI comparison!")
    
    return results_file

if __name__ == "__main__":
    main()
